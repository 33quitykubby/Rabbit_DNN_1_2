{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rabbit_DNN_9_newtwork1_L2norm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/33quitykubby/Rabbit_DNN_1_2/blob/main/Rabbit_DNN_9_newtwork1_L2norm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndo0gsKs29oE"
      },
      "source": [
        "# 2層DNN\n",
        "\n",
        "サンプルコード2_1_network_modified.ipynb\n",
        "写経  \n",
        "L2正則化(Ridge)を適用\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFawz7zCioGw"
      },
      "source": [
        "# 日本時間にする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqk7xVQXilAv",
        "outputId": "6c009f4e-47f8-463f-9c92-97f7bd5c82e5"
      },
      "source": [
        "  !rm /etc/localtime\n",
        "  !ln -s /usr/share/zoneinfo/Asia/Tokyo /etc/localtime\n",
        "  !date"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Apr 28 23:11:48 JST 2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XSgZcpT4tkC"
      },
      "source": [
        "# ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hlcGt_j4tkD"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import librosa\n",
        "\n",
        "import datetime\n",
        "\n",
        "import gc\n",
        "\n",
        "from sklearn.datasets import load_boston\n",
        "from pandas import DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3Kfi-5YVRYV",
        "outputId": "a52002da-83a6-4594-b28d-f6a8ec9b0c2d"
      },
      "source": [
        "#開始時刻\n",
        "start_time = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "print(\"start_time=\",start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start_time= 2021-04-28 23:11:49.042136+09:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdzrJm_XYr17"
      },
      "source": [
        "# 乱数シードの初期化\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNUHyFvYF1_Z"
      },
      "source": [
        "import os \n",
        "import numpy as np\n",
        "from sklearn import model_selection\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "COMMON_SEED = 0\n",
        "STANDARD_SEED = 0\n",
        "NP_SEED = 0\n",
        "TF_SEED = 0 \n",
        "\n",
        "# np.random.seed(STANDARD_SEED)\n",
        "# random.seed(NP_SEED)\n",
        "# tf.random.set_seed(TF_SEED)\n",
        "\n",
        "def seed_everything():\n",
        "    random.seed(STANDARD_SEED)\n",
        "    os.environ['PYTHONHASHSEED'] = str(COMMON_SEED)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "    np.random.seed(NP_SEED)\n",
        "    tf.random.set_seed(TF_SEED)\n",
        "    session_conf = tf.compat.v1.ConfigProto(\n",
        "        intra_op_parallelism_threads=1,\n",
        "        inter_op_parallelism_threads=1\n",
        "    )\n",
        "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "    tf.compat.v1.keras.backend.set_session(sess)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AOmh1f2uhww"
      },
      "source": [
        "#乱数シード固定\n",
        "\n",
        "seed_everything()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3KtRk3Eipe8"
      },
      "source": [
        "# パス定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYt61qQ_SJAA",
        "outputId": "ea93c4e0-1541-4d90-f6ea-5573bebf9548"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EErzFsxdELb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOFeuuWHcP6U"
      },
      "source": [
        "## class Relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni4wSFj1cSay"
      },
      "source": [
        "class Relu:\n",
        "  def __init__(self):\n",
        "    self.mask = None\n",
        "  \n",
        "  def forward(self, x):\n",
        "    self.mask = ( x <= 0 )\n",
        "    out = x.copy()\n",
        "    # Trueの箇所を0にする\n",
        "    out[self.mask] = 0\n",
        "  \n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    self.mask = ( dout > 0)\n",
        "    out = dout.copy()\n",
        "    # Trueの箇所を0にする\n",
        "    dout[self.mask] = 0\n",
        "    dx = dout\n",
        "\n",
        "    return dx\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNNn8T4Fdo9X"
      },
      "source": [
        "## class Affine（全結合層）\n",
        "\n",
        "$$dout = x・W + b$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uPXKlnpdu5M"
      },
      "source": [
        "class Affine:\n",
        "  def __init__(self, W, b):\n",
        "    self.W = W\n",
        "    self.b = b\n",
        "\n",
        "    self.x = None\n",
        "    self.original_x_shape = None\n",
        "    \n",
        "    #重み、バイアスの微分\n",
        "    self.dW = None\n",
        "    self.db = None\n",
        "  \n",
        "  def forward(self, x):\n",
        "    #　テンソル対応\n",
        "    self.original_x_shape = x.shape\n",
        "    # print(\"x.org.shape=\",self.original_x_shape)\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    self.x = x\n",
        "    # print(\"x.shape=\",self.x.shape)\n",
        "\n",
        "    out = np.dot(self.x, self.W) + self.b\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dx = np.dot(dout, self.W.T)\n",
        "    self.dW = np.dot(self.x.T, dout)\n",
        "    self.db = np.sum(dout,axis=0)\n",
        "\n",
        "    # 入力データの形状にもどしてあげる\n",
        "    dx = dx.reshape(*self.original_x_shape)\n",
        "    return dx\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYmTI4E9HmEg"
      },
      "source": [
        "## class SoftmaxWithLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiB4cUqWItN5"
      },
      "source": [
        "class SoftmaxWithLoss:\n",
        "  def __init__(self):\n",
        "    self.loss = None\n",
        "    self.y = None\n",
        "    self.d = None\n",
        "\n",
        "  def softmax(self, x):\n",
        "    if x.ndim == 2:\n",
        "      x = x.T\n",
        "      x = x - np.max(x, axis=0)\n",
        "      y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "      return y.T\n",
        "\n",
        "    x = x - np.max(x) # オーバーフロー対策\n",
        "    return np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "  def cross_entropy_error(self, d, y):\n",
        "    if y.ndim == 1:\n",
        "      d = d.reshape(1, d.size)\n",
        "      y = y.reshape(1, y.size)\n",
        "\n",
        "    #教師データがone-hotの場合、正解ラベルのインデックスに変換\n",
        "    if d.size == y.size:\n",
        "      d = d.argmax(axis=1)\n",
        "\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), d] + 1e-7)) / batch_size\n",
        "\n",
        "  def forward(self, x, d):\n",
        "    self.d = d\n",
        "    self.y = self.softmax(x)\n",
        "    self.loss = self.cross_entropy_error(self.d, self.y)\n",
        "\n",
        "    return self.loss\n",
        "\n",
        "  def backward(self, dout=1):\n",
        "    batch_size = self.d.shape[0]\n",
        "    if self.d.size == self.y.size: # 教師データがone-hotの場合\n",
        "      dx = (self.y - self.d) / batch_size\n",
        "    else:\n",
        "      dx = self.y.copy()\n",
        "      dx[np.arange(batch_size), self.d] -= 1\n",
        "      dx = dx / batch_size\n",
        "\n",
        "    return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqVbCZUyk7L2"
      },
      "source": [
        "# 2層DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59aLTTtZk_Kj"
      },
      "source": [
        "import collections\n",
        "\n",
        "class TwoLayerNet:\n",
        "\n",
        "  #input_size 入力層のノード数\n",
        "  # hidden_size:隠れ層のノード数\n",
        "  # output_size:出力層のノード数\n",
        "  # weight_init_std:重みの初期化方法\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size, weight_init_std =0.01):\n",
        "    #重みの初期化\n",
        "    self.params={}\n",
        "    self.params['W1'] = weight_init_std * np.random.randn(input_size,hidden_size)\n",
        "    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "    self.params['b1'] = np.zeros(hidden_size)\n",
        "    self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "    #レイヤの生成\n",
        "    self.layers = collections.OrderedDict()\n",
        "    self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
        "    self.layers['Relu1'] = Relu()\n",
        "    self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
        "\n",
        "    self.lastLayer = SoftmaxWithLoss()\n",
        "\n",
        "  #順伝播\n",
        "  def predict(self, x):\n",
        "    for layer in self.layers.values():\n",
        "      x = layer.forward(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  #誤差\n",
        "  def loss(self, x, d):\n",
        "    y = self.predict(x)\n",
        "    return self.lastLayer.forward(y, d)\n",
        "\n",
        "  #精度\n",
        "  def accuracy(self, x, d):\n",
        "    y = self.predict(x)\n",
        "    y = np.argmax(y, axis=1)\n",
        "    if d.ndim != 1 :\n",
        "      d = np.argmax(d, axis=1)\n",
        "\n",
        "    accuracy = np.sum(y == d) / float(x.shape[0])\n",
        "    return accuracy\n",
        "\n",
        "  # 勾配\n",
        "  def gradient(self, x, d):\n",
        "    #forward\n",
        "    self.loss(x, d)\n",
        "\n",
        "    #backward\n",
        "    dout = 1\n",
        "    dout = self.lastLayer.backward(dout)\n",
        "\n",
        "    layers = list(self.layers.values())\n",
        "    layers.reverse()\n",
        "    for layer in layers:\n",
        "      dout = layer.backward(dout)\n",
        "\n",
        "    #設定\n",
        "    grad = {}\n",
        "    grad['W1'], grad['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db \n",
        "    grad['W2'], grad['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db \n",
        "\n",
        "    return grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZPtEEH2RXXk"
      },
      "source": [
        "# MNISTデータ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rObaIT6RaVS"
      },
      "source": [
        "import gzip\n",
        "import pickle\n",
        "\n",
        "url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
        "key_file = {\n",
        "    'train_img':'train-images-idx3-ubyte.gz',\n",
        "    'train_label':'train-labels-idx1-ubyte.gz',\n",
        "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
        "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "# dataset_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "dataset_dir = '/content/drive/MyDrive/RabbitChallenge/DNN_code_colab_lesson_1_2/data'\n",
        "save_file = dataset_dir + \"/mnist.pkl\"\n",
        "\n",
        "train_num = 60000\n",
        "test_num = 10000\n",
        "img_dim = (1, 28, 28)\n",
        "img_size = 784\n",
        "\n",
        "\n",
        "def _download(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    if os.path.exists(file_path):\n",
        "        return\n",
        "\n",
        "    print(\"Downloading \" + file_name + \" ... \")\n",
        "    urllib.request.urlretrieve(url_base + file_name, file_path)\n",
        "    print(\"Done\")\n",
        "    \n",
        "def download_mnist():\n",
        "    for v in key_file.values():\n",
        "       _download(v)\n",
        "        \n",
        "def _load_label(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return labels\n",
        "\n",
        "def _load_img(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")    \n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(-1, img_size)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return data\n",
        "    \n",
        "def _convert_numpy():\n",
        "    dataset = {}\n",
        "    dataset['train_img'] =  _load_img(key_file['train_img'])\n",
        "    dataset['train_label'] = _load_label(key_file['train_label'])    \n",
        "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
        "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "def init_mnist():\n",
        "    download_mnist()\n",
        "    dataset = _convert_numpy()\n",
        "    print(\"Creating pickle file ...\")\n",
        "    with open(save_file, 'wb') as f:\n",
        "        pickle.dump(dataset, f, -1)\n",
        "    print(\"Done!\")\n",
        "\n",
        "def _change_one_hot_label(X):\n",
        "    T = np.zeros((X.size, 10))\n",
        "    for idx, row in enumerate(T):\n",
        "        row[X[idx]] = 1\n",
        "        \n",
        "    return T\n",
        "    \n",
        "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
        "    \"\"\"MNISTデータセットの読み込み\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    normalize : 画像のピクセル値を0.0~1.0に正規化する\n",
        "    one_hot_label : \n",
        "        one_hot_labelがTrueの場合、ラベルはone-hot配列として返す\n",
        "        one-hot配列とは、たとえば[0,0,1,0,0,0,0,0,0,0]のような配列\n",
        "    flatten : 画像を一次元配列に平にするかどうか \n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    (訓練画像, 訓練ラベル), (テスト画像, テストラベル)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_file):\n",
        "        init_mnist()\n",
        "        \n",
        "    with open(save_file, 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    \n",
        "    if normalize:\n",
        "        for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].astype(np.float32)\n",
        "            dataset[key] /= 255.0\n",
        "            \n",
        "    if one_hot_label:\n",
        "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
        "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])\n",
        "    \n",
        "    if not flatten:\n",
        "         for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
        "\n",
        "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhGKjzPiq_Qf"
      },
      "source": [
        "# MNIST Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iF7zNYxrDuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82dcd7b3-ebe8-4bda-dd83-0efc29f8cbf8"
      },
      "source": [
        "# データの読み込み\n",
        "(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "print(\"data read finish\")\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=40, output_size=10)\n",
        "\n",
        "iters_num = 5000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "train_loss_list = []\n",
        "accuracies_train = []\n",
        "accuracies_test = []\n",
        "\n",
        "plot_interval = 10\n",
        "\n",
        "rate = 0.2\n",
        "\n",
        "for i in range(iters_num):\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\n",
        "  x_batch = x_train[batch_mask]\n",
        "  d_batch = d_train[batch_mask]\n",
        "\n",
        "  # 勾配\n",
        "  grad = network.gradient(x_batch, d_batch)\n",
        "\n",
        "  for key in ('W1', 'W2', 'b1', 'b2'):\n",
        "    grad[key] += rate * network.params[key]\n",
        "    network.params[key] -= learning_rate * grad[key] # SGD\n",
        "\n",
        "  loss = network.loss(x_batch, d_batch)\n",
        "  train_loss_list.append(loss)\n",
        "\n",
        "  if (i + 1) % plot_interval == 0:\n",
        "    accr_test = network.accuracy(x_test, d_test)\n",
        "    accuracies_test.append(accr_test)\n",
        "    accr_train = network.accuracy(x_batch, d_batch)\n",
        "    accuracies_train.append(accr_train)\n",
        "\n",
        "    print('Generation: ' + str(i+1)+ 'Accuracy(Training)=' + str(accr_train))\n",
        "    print('             :'+ str(i+1)+ 'Accuracy(Test)=' + str(accr_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data read finish\n",
            "Generation: 10Accuracy(Training)=0.07\n",
            "             :10Accuracy(Test)=0.0981\n",
            "Generation: 20Accuracy(Training)=0.12\n",
            "             :20Accuracy(Test)=0.1105\n",
            "Generation: 30Accuracy(Training)=0.18\n",
            "             :30Accuracy(Test)=0.1201\n",
            "Generation: 40Accuracy(Training)=0.09\n",
            "             :40Accuracy(Test)=0.1176\n",
            "Generation: 50Accuracy(Training)=0.14\n",
            "             :50Accuracy(Test)=0.1184\n",
            "Generation: 60Accuracy(Training)=0.12\n",
            "             :60Accuracy(Test)=0.1455\n",
            "Generation: 70Accuracy(Training)=0.15\n",
            "             :70Accuracy(Test)=0.1797\n",
            "Generation: 80Accuracy(Training)=0.19\n",
            "             :80Accuracy(Test)=0.2019\n",
            "Generation: 90Accuracy(Training)=0.16\n",
            "             :90Accuracy(Test)=0.2306\n",
            "Generation: 100Accuracy(Training)=0.25\n",
            "             :100Accuracy(Test)=0.2521\n",
            "Generation: 110Accuracy(Training)=0.27\n",
            "             :110Accuracy(Test)=0.2557\n",
            "Generation: 120Accuracy(Training)=0.31\n",
            "             :120Accuracy(Test)=0.2636\n",
            "Generation: 130Accuracy(Training)=0.3\n",
            "             :130Accuracy(Test)=0.2956\n",
            "Generation: 140Accuracy(Training)=0.28\n",
            "             :140Accuracy(Test)=0.2765\n",
            "Generation: 150Accuracy(Training)=0.24\n",
            "             :150Accuracy(Test)=0.271\n",
            "Generation: 160Accuracy(Training)=0.21\n",
            "             :160Accuracy(Test)=0.2664\n",
            "Generation: 170Accuracy(Training)=0.21\n",
            "             :170Accuracy(Test)=0.2582\n",
            "Generation: 180Accuracy(Training)=0.23\n",
            "             :180Accuracy(Test)=0.2382\n",
            "Generation: 190Accuracy(Training)=0.22\n",
            "             :190Accuracy(Test)=0.2262\n",
            "Generation: 200Accuracy(Training)=0.18\n",
            "             :200Accuracy(Test)=0.1565\n",
            "Generation: 210Accuracy(Training)=0.19\n",
            "             :210Accuracy(Test)=0.1469\n",
            "Generation: 220Accuracy(Training)=0.12\n",
            "             :220Accuracy(Test)=0.1096\n",
            "Generation: 230Accuracy(Training)=0.09\n",
            "             :230Accuracy(Test)=0.1088\n",
            "Generation: 240Accuracy(Training)=0.12\n",
            "             :240Accuracy(Test)=0.0994\n",
            "Generation: 250Accuracy(Training)=0.1\n",
            "             :250Accuracy(Test)=0.1017\n",
            "Generation: 260Accuracy(Training)=0.11\n",
            "             :260Accuracy(Test)=0.0995\n",
            "Generation: 270Accuracy(Training)=0.13\n",
            "             :270Accuracy(Test)=0.1374\n",
            "Generation: 280Accuracy(Training)=0.12\n",
            "             :280Accuracy(Test)=0.0991\n",
            "Generation: 290Accuracy(Training)=0.14\n",
            "             :290Accuracy(Test)=0.0981\n",
            "Generation: 300Accuracy(Training)=0.16\n",
            "             :300Accuracy(Test)=0.098\n",
            "Generation: 310Accuracy(Training)=0.14\n",
            "             :310Accuracy(Test)=0.098\n",
            "Generation: 320Accuracy(Training)=0.07\n",
            "             :320Accuracy(Test)=0.098\n",
            "Generation: 330Accuracy(Training)=0.12\n",
            "             :330Accuracy(Test)=0.0981\n",
            "Generation: 340Accuracy(Training)=0.1\n",
            "             :340Accuracy(Test)=0.098\n",
            "Generation: 350Accuracy(Training)=0.09\n",
            "             :350Accuracy(Test)=0.0997\n",
            "Generation: 360Accuracy(Training)=0.1\n",
            "             :360Accuracy(Test)=0.0983\n",
            "Generation: 370Accuracy(Training)=0.12\n",
            "             :370Accuracy(Test)=0.0981\n",
            "Generation: 380Accuracy(Training)=0.08\n",
            "             :380Accuracy(Test)=0.0985\n",
            "Generation: 390Accuracy(Training)=0.13\n",
            "             :390Accuracy(Test)=0.0983\n",
            "Generation: 400Accuracy(Training)=0.09\n",
            "             :400Accuracy(Test)=0.0983\n",
            "Generation: 410Accuracy(Training)=0.08\n",
            "             :410Accuracy(Test)=0.098\n",
            "Generation: 420Accuracy(Training)=0.19\n",
            "             :420Accuracy(Test)=0.098\n",
            "Generation: 430Accuracy(Training)=0.09\n",
            "             :430Accuracy(Test)=0.098\n",
            "Generation: 440Accuracy(Training)=0.08\n",
            "             :440Accuracy(Test)=0.098\n",
            "Generation: 450Accuracy(Training)=0.11\n",
            "             :450Accuracy(Test)=0.098\n",
            "Generation: 460Accuracy(Training)=0.09\n",
            "             :460Accuracy(Test)=0.098\n",
            "Generation: 470Accuracy(Training)=0.11\n",
            "             :470Accuracy(Test)=0.098\n",
            "Generation: 480Accuracy(Training)=0.07\n",
            "             :480Accuracy(Test)=0.098\n",
            "Generation: 490Accuracy(Training)=0.1\n",
            "             :490Accuracy(Test)=0.0981\n",
            "Generation: 500Accuracy(Training)=0.09\n",
            "             :500Accuracy(Test)=0.0981\n",
            "Generation: 510Accuracy(Training)=0.09\n",
            "             :510Accuracy(Test)=0.098\n",
            "Generation: 520Accuracy(Training)=0.05\n",
            "             :520Accuracy(Test)=0.0981\n",
            "Generation: 530Accuracy(Training)=0.08\n",
            "             :530Accuracy(Test)=0.0981\n",
            "Generation: 540Accuracy(Training)=0.06\n",
            "             :540Accuracy(Test)=0.1003\n",
            "Generation: 550Accuracy(Training)=0.09\n",
            "             :550Accuracy(Test)=0.1459\n",
            "Generation: 560Accuracy(Training)=0.14\n",
            "             :560Accuracy(Test)=0.1093\n",
            "Generation: 570Accuracy(Training)=0.13\n",
            "             :570Accuracy(Test)=0.1704\n",
            "Generation: 580Accuracy(Training)=0.17\n",
            "             :580Accuracy(Test)=0.1483\n",
            "Generation: 590Accuracy(Training)=0.17\n",
            "             :590Accuracy(Test)=0.1447\n",
            "Generation: 600Accuracy(Training)=0.07\n",
            "             :600Accuracy(Test)=0.1125\n",
            "Generation: 610Accuracy(Training)=0.13\n",
            "             :610Accuracy(Test)=0.1294\n",
            "Generation: 620Accuracy(Training)=0.13\n",
            "             :620Accuracy(Test)=0.1098\n",
            "Generation: 630Accuracy(Training)=0.14\n",
            "             :630Accuracy(Test)=0.1004\n",
            "Generation: 640Accuracy(Training)=0.13\n",
            "             :640Accuracy(Test)=0.1068\n",
            "Generation: 650Accuracy(Training)=0.18\n",
            "             :650Accuracy(Test)=0.1764\n",
            "Generation: 660Accuracy(Training)=0.2\n",
            "             :660Accuracy(Test)=0.1858\n",
            "Generation: 670Accuracy(Training)=0.2\n",
            "             :670Accuracy(Test)=0.1868\n",
            "Generation: 680Accuracy(Training)=0.18\n",
            "             :680Accuracy(Test)=0.1699\n",
            "Generation: 690Accuracy(Training)=0.11\n",
            "             :690Accuracy(Test)=0.1131\n",
            "Generation: 700Accuracy(Training)=0.09\n",
            "             :700Accuracy(Test)=0.1039\n",
            "Generation: 710Accuracy(Training)=0.17\n",
            "             :710Accuracy(Test)=0.134\n",
            "Generation: 720Accuracy(Training)=0.13\n",
            "             :720Accuracy(Test)=0.1687\n",
            "Generation: 730Accuracy(Training)=0.17\n",
            "             :730Accuracy(Test)=0.1819\n",
            "Generation: 740Accuracy(Training)=0.25\n",
            "             :740Accuracy(Test)=0.1633\n",
            "Generation: 750Accuracy(Training)=0.18\n",
            "             :750Accuracy(Test)=0.1425\n",
            "Generation: 760Accuracy(Training)=0.2\n",
            "             :760Accuracy(Test)=0.1797\n",
            "Generation: 770Accuracy(Training)=0.19\n",
            "             :770Accuracy(Test)=0.1879\n",
            "Generation: 780Accuracy(Training)=0.16\n",
            "             :780Accuracy(Test)=0.1673\n",
            "Generation: 790Accuracy(Training)=0.15\n",
            "             :790Accuracy(Test)=0.1674\n",
            "Generation: 800Accuracy(Training)=0.17\n",
            "             :800Accuracy(Test)=0.1447\n",
            "Generation: 810Accuracy(Training)=0.16\n",
            "             :810Accuracy(Test)=0.1499\n",
            "Generation: 820Accuracy(Training)=0.17\n",
            "             :820Accuracy(Test)=0.1829\n",
            "Generation: 830Accuracy(Training)=0.19\n",
            "             :830Accuracy(Test)=0.1676\n",
            "Generation: 840Accuracy(Training)=0.18\n",
            "             :840Accuracy(Test)=0.1943\n",
            "Generation: 850Accuracy(Training)=0.13\n",
            "             :850Accuracy(Test)=0.1866\n",
            "Generation: 860Accuracy(Training)=0.23\n",
            "             :860Accuracy(Test)=0.1956\n",
            "Generation: 870Accuracy(Training)=0.2\n",
            "             :870Accuracy(Test)=0.1932\n",
            "Generation: 880Accuracy(Training)=0.17\n",
            "             :880Accuracy(Test)=0.1354\n",
            "Generation: 890Accuracy(Training)=0.1\n",
            "             :890Accuracy(Test)=0.1159\n",
            "Generation: 900Accuracy(Training)=0.19\n",
            "             :900Accuracy(Test)=0.146\n",
            "Generation: 910Accuracy(Training)=0.16\n",
            "             :910Accuracy(Test)=0.1318\n",
            "Generation: 920Accuracy(Training)=0.15\n",
            "             :920Accuracy(Test)=0.1358\n",
            "Generation: 930Accuracy(Training)=0.23\n",
            "             :930Accuracy(Test)=0.1713\n",
            "Generation: 940Accuracy(Training)=0.14\n",
            "             :940Accuracy(Test)=0.1178\n",
            "Generation: 950Accuracy(Training)=0.18\n",
            "             :950Accuracy(Test)=0.133\n",
            "Generation: 960Accuracy(Training)=0.12\n",
            "             :960Accuracy(Test)=0.1311\n",
            "Generation: 970Accuracy(Training)=0.16\n",
            "             :970Accuracy(Test)=0.2197\n",
            "Generation: 980Accuracy(Training)=0.22\n",
            "             :980Accuracy(Test)=0.1917\n",
            "Generation: 990Accuracy(Training)=0.18\n",
            "             :990Accuracy(Test)=0.1745\n",
            "Generation: 1000Accuracy(Training)=0.17\n",
            "             :1000Accuracy(Test)=0.1716\n",
            "Generation: 1010Accuracy(Training)=0.17\n",
            "             :1010Accuracy(Test)=0.1498\n",
            "Generation: 1020Accuracy(Training)=0.16\n",
            "             :1020Accuracy(Test)=0.1676\n",
            "Generation: 1030Accuracy(Training)=0.2\n",
            "             :1030Accuracy(Test)=0.2035\n",
            "Generation: 1040Accuracy(Training)=0.22\n",
            "             :1040Accuracy(Test)=0.188\n",
            "Generation: 1050Accuracy(Training)=0.17\n",
            "             :1050Accuracy(Test)=0.1863\n",
            "Generation: 1060Accuracy(Training)=0.18\n",
            "             :1060Accuracy(Test)=0.177\n",
            "Generation: 1070Accuracy(Training)=0.17\n",
            "             :1070Accuracy(Test)=0.1703\n",
            "Generation: 1080Accuracy(Training)=0.18\n",
            "             :1080Accuracy(Test)=0.1833\n",
            "Generation: 1090Accuracy(Training)=0.26\n",
            "             :1090Accuracy(Test)=0.2409\n",
            "Generation: 1100Accuracy(Training)=0.24\n",
            "             :1100Accuracy(Test)=0.2588\n",
            "Generation: 1110Accuracy(Training)=0.31\n",
            "             :1110Accuracy(Test)=0.2763\n",
            "Generation: 1120Accuracy(Training)=0.22\n",
            "             :1120Accuracy(Test)=0.2831\n",
            "Generation: 1130Accuracy(Training)=0.34\n",
            "             :1130Accuracy(Test)=0.306\n",
            "Generation: 1140Accuracy(Training)=0.26\n",
            "             :1140Accuracy(Test)=0.2196\n",
            "Generation: 1150Accuracy(Training)=0.35\n",
            "             :1150Accuracy(Test)=0.2917\n",
            "Generation: 1160Accuracy(Training)=0.33\n",
            "             :1160Accuracy(Test)=0.2776\n",
            "Generation: 1170Accuracy(Training)=0.3\n",
            "             :1170Accuracy(Test)=0.222\n",
            "Generation: 1180Accuracy(Training)=0.21\n",
            "             :1180Accuracy(Test)=0.2221\n",
            "Generation: 1190Accuracy(Training)=0.45\n",
            "             :1190Accuracy(Test)=0.3702\n",
            "Generation: 1200Accuracy(Training)=0.34\n",
            "             :1200Accuracy(Test)=0.3581\n",
            "Generation: 1210Accuracy(Training)=0.37\n",
            "             :1210Accuracy(Test)=0.2577\n",
            "Generation: 1220Accuracy(Training)=0.22\n",
            "             :1220Accuracy(Test)=0.2863\n",
            "Generation: 1230Accuracy(Training)=0.22\n",
            "             :1230Accuracy(Test)=0.3233\n",
            "Generation: 1240Accuracy(Training)=0.31\n",
            "             :1240Accuracy(Test)=0.2689\n",
            "Generation: 1250Accuracy(Training)=0.3\n",
            "             :1250Accuracy(Test)=0.2806\n",
            "Generation: 1260Accuracy(Training)=0.4\n",
            "             :1260Accuracy(Test)=0.3832\n",
            "Generation: 1270Accuracy(Training)=0.39\n",
            "             :1270Accuracy(Test)=0.3247\n",
            "Generation: 1280Accuracy(Training)=0.45\n",
            "             :1280Accuracy(Test)=0.3542\n",
            "Generation: 1290Accuracy(Training)=0.42\n",
            "             :1290Accuracy(Test)=0.3638\n",
            "Generation: 1300Accuracy(Training)=0.44\n",
            "             :1300Accuracy(Test)=0.4373\n",
            "Generation: 1310Accuracy(Training)=0.31\n",
            "             :1310Accuracy(Test)=0.3824\n",
            "Generation: 1320Accuracy(Training)=0.44\n",
            "             :1320Accuracy(Test)=0.4284\n",
            "Generation: 1330Accuracy(Training)=0.51\n",
            "             :1330Accuracy(Test)=0.429\n",
            "Generation: 1340Accuracy(Training)=0.35\n",
            "             :1340Accuracy(Test)=0.4645\n",
            "Generation: 1350Accuracy(Training)=0.43\n",
            "             :1350Accuracy(Test)=0.4089\n",
            "Generation: 1360Accuracy(Training)=0.43\n",
            "             :1360Accuracy(Test)=0.4122\n",
            "Generation: 1370Accuracy(Training)=0.37\n",
            "             :1370Accuracy(Test)=0.4205\n",
            "Generation: 1380Accuracy(Training)=0.35\n",
            "             :1380Accuracy(Test)=0.3964\n",
            "Generation: 1390Accuracy(Training)=0.35\n",
            "             :1390Accuracy(Test)=0.3141\n",
            "Generation: 1400Accuracy(Training)=0.54\n",
            "             :1400Accuracy(Test)=0.4557\n",
            "Generation: 1410Accuracy(Training)=0.39\n",
            "             :1410Accuracy(Test)=0.379\n",
            "Generation: 1420Accuracy(Training)=0.5\n",
            "             :1420Accuracy(Test)=0.4742\n",
            "Generation: 1430Accuracy(Training)=0.41\n",
            "             :1430Accuracy(Test)=0.4514\n",
            "Generation: 1440Accuracy(Training)=0.49\n",
            "             :1440Accuracy(Test)=0.4954\n",
            "Generation: 1450Accuracy(Training)=0.53\n",
            "             :1450Accuracy(Test)=0.4783\n",
            "Generation: 1460Accuracy(Training)=0.5\n",
            "             :1460Accuracy(Test)=0.4584\n",
            "Generation: 1470Accuracy(Training)=0.46\n",
            "             :1470Accuracy(Test)=0.4721\n",
            "Generation: 1480Accuracy(Training)=0.45\n",
            "             :1480Accuracy(Test)=0.4052\n",
            "Generation: 1490Accuracy(Training)=0.48\n",
            "             :1490Accuracy(Test)=0.5024\n",
            "Generation: 1500Accuracy(Training)=0.49\n",
            "             :1500Accuracy(Test)=0.4919\n",
            "Generation: 1510Accuracy(Training)=0.46\n",
            "             :1510Accuracy(Test)=0.4174\n",
            "Generation: 1520Accuracy(Training)=0.57\n",
            "             :1520Accuracy(Test)=0.4773\n",
            "Generation: 1530Accuracy(Training)=0.5\n",
            "             :1530Accuracy(Test)=0.5356\n",
            "Generation: 1540Accuracy(Training)=0.5\n",
            "             :1540Accuracy(Test)=0.4788\n",
            "Generation: 1550Accuracy(Training)=0.45\n",
            "             :1550Accuracy(Test)=0.4934\n",
            "Generation: 1560Accuracy(Training)=0.51\n",
            "             :1560Accuracy(Test)=0.4921\n",
            "Generation: 1570Accuracy(Training)=0.58\n",
            "             :1570Accuracy(Test)=0.4847\n",
            "Generation: 1580Accuracy(Training)=0.53\n",
            "             :1580Accuracy(Test)=0.5088\n",
            "Generation: 1590Accuracy(Training)=0.41\n",
            "             :1590Accuracy(Test)=0.4212\n",
            "Generation: 1600Accuracy(Training)=0.4\n",
            "             :1600Accuracy(Test)=0.3898\n",
            "Generation: 1610Accuracy(Training)=0.51\n",
            "             :1610Accuracy(Test)=0.4955\n",
            "Generation: 1620Accuracy(Training)=0.55\n",
            "             :1620Accuracy(Test)=0.5696\n",
            "Generation: 1630Accuracy(Training)=0.57\n",
            "             :1630Accuracy(Test)=0.5191\n",
            "Generation: 1640Accuracy(Training)=0.45\n",
            "             :1640Accuracy(Test)=0.4664\n",
            "Generation: 1650Accuracy(Training)=0.61\n",
            "             :1650Accuracy(Test)=0.4921\n",
            "Generation: 1660Accuracy(Training)=0.51\n",
            "             :1660Accuracy(Test)=0.4673\n",
            "Generation: 1670Accuracy(Training)=0.5\n",
            "             :1670Accuracy(Test)=0.5013\n",
            "Generation: 1680Accuracy(Training)=0.45\n",
            "             :1680Accuracy(Test)=0.4517\n",
            "Generation: 1690Accuracy(Training)=0.58\n",
            "             :1690Accuracy(Test)=0.5088\n",
            "Generation: 1700Accuracy(Training)=0.59\n",
            "             :1700Accuracy(Test)=0.5353\n",
            "Generation: 1710Accuracy(Training)=0.59\n",
            "             :1710Accuracy(Test)=0.5005\n",
            "Generation: 1720Accuracy(Training)=0.57\n",
            "             :1720Accuracy(Test)=0.4542\n",
            "Generation: 1730Accuracy(Training)=0.55\n",
            "             :1730Accuracy(Test)=0.5149\n",
            "Generation: 1740Accuracy(Training)=0.48\n",
            "             :1740Accuracy(Test)=0.4969\n",
            "Generation: 1750Accuracy(Training)=0.53\n",
            "             :1750Accuracy(Test)=0.5023\n",
            "Generation: 1760Accuracy(Training)=0.51\n",
            "             :1760Accuracy(Test)=0.5111\n",
            "Generation: 1770Accuracy(Training)=0.66\n",
            "             :1770Accuracy(Test)=0.5701\n",
            "Generation: 1780Accuracy(Training)=0.51\n",
            "             :1780Accuracy(Test)=0.5223\n",
            "Generation: 1790Accuracy(Training)=0.46\n",
            "             :1790Accuracy(Test)=0.475\n",
            "Generation: 1800Accuracy(Training)=0.58\n",
            "             :1800Accuracy(Test)=0.509\n",
            "Generation: 1810Accuracy(Training)=0.63\n",
            "             :1810Accuracy(Test)=0.5598\n",
            "Generation: 1820Accuracy(Training)=0.55\n",
            "             :1820Accuracy(Test)=0.5378\n",
            "Generation: 1830Accuracy(Training)=0.51\n",
            "             :1830Accuracy(Test)=0.5129\n",
            "Generation: 1840Accuracy(Training)=0.48\n",
            "             :1840Accuracy(Test)=0.4932\n",
            "Generation: 1850Accuracy(Training)=0.5\n",
            "             :1850Accuracy(Test)=0.5234\n",
            "Generation: 1860Accuracy(Training)=0.5\n",
            "             :1860Accuracy(Test)=0.5288\n",
            "Generation: 1870Accuracy(Training)=0.56\n",
            "             :1870Accuracy(Test)=0.4271\n",
            "Generation: 1880Accuracy(Training)=0.62\n",
            "             :1880Accuracy(Test)=0.526\n",
            "Generation: 1890Accuracy(Training)=0.55\n",
            "             :1890Accuracy(Test)=0.5003\n",
            "Generation: 1900Accuracy(Training)=0.61\n",
            "             :1900Accuracy(Test)=0.543\n",
            "Generation: 1910Accuracy(Training)=0.51\n",
            "             :1910Accuracy(Test)=0.5083\n",
            "Generation: 1920Accuracy(Training)=0.52\n",
            "             :1920Accuracy(Test)=0.5235\n",
            "Generation: 1930Accuracy(Training)=0.63\n",
            "             :1930Accuracy(Test)=0.5777\n",
            "Generation: 1940Accuracy(Training)=0.6\n",
            "             :1940Accuracy(Test)=0.5236\n",
            "Generation: 1950Accuracy(Training)=0.53\n",
            "             :1950Accuracy(Test)=0.5096\n",
            "Generation: 1960Accuracy(Training)=0.58\n",
            "             :1960Accuracy(Test)=0.5755\n",
            "Generation: 1970Accuracy(Training)=0.59\n",
            "             :1970Accuracy(Test)=0.548\n",
            "Generation: 1980Accuracy(Training)=0.56\n",
            "             :1980Accuracy(Test)=0.49\n",
            "Generation: 1990Accuracy(Training)=0.5\n",
            "             :1990Accuracy(Test)=0.5519\n",
            "Generation: 2000Accuracy(Training)=0.53\n",
            "             :2000Accuracy(Test)=0.5687\n",
            "Generation: 2010Accuracy(Training)=0.63\n",
            "             :2010Accuracy(Test)=0.5841\n",
            "Generation: 2020Accuracy(Training)=0.5\n",
            "             :2020Accuracy(Test)=0.5205\n",
            "Generation: 2030Accuracy(Training)=0.61\n",
            "             :2030Accuracy(Test)=0.5333\n",
            "Generation: 2040Accuracy(Training)=0.51\n",
            "             :2040Accuracy(Test)=0.5263\n",
            "Generation: 2050Accuracy(Training)=0.55\n",
            "             :2050Accuracy(Test)=0.4922\n",
            "Generation: 2060Accuracy(Training)=0.57\n",
            "             :2060Accuracy(Test)=0.6006\n",
            "Generation: 2070Accuracy(Training)=0.58\n",
            "             :2070Accuracy(Test)=0.5753\n",
            "Generation: 2080Accuracy(Training)=0.63\n",
            "             :2080Accuracy(Test)=0.4827\n",
            "Generation: 2090Accuracy(Training)=0.48\n",
            "             :2090Accuracy(Test)=0.5117\n",
            "Generation: 2100Accuracy(Training)=0.67\n",
            "             :2100Accuracy(Test)=0.5793\n",
            "Generation: 2110Accuracy(Training)=0.55\n",
            "             :2110Accuracy(Test)=0.5455\n",
            "Generation: 2120Accuracy(Training)=0.52\n",
            "             :2120Accuracy(Test)=0.5304\n",
            "Generation: 2130Accuracy(Training)=0.53\n",
            "             :2130Accuracy(Test)=0.5478\n",
            "Generation: 2140Accuracy(Training)=0.64\n",
            "             :2140Accuracy(Test)=0.6124\n",
            "Generation: 2150Accuracy(Training)=0.53\n",
            "             :2150Accuracy(Test)=0.6262\n",
            "Generation: 2160Accuracy(Training)=0.54\n",
            "             :2160Accuracy(Test)=0.5372\n",
            "Generation: 2170Accuracy(Training)=0.58\n",
            "             :2170Accuracy(Test)=0.5619\n",
            "Generation: 2180Accuracy(Training)=0.51\n",
            "             :2180Accuracy(Test)=0.5106\n",
            "Generation: 2190Accuracy(Training)=0.6\n",
            "             :2190Accuracy(Test)=0.567\n",
            "Generation: 2200Accuracy(Training)=0.62\n",
            "             :2200Accuracy(Test)=0.5333\n",
            "Generation: 2210Accuracy(Training)=0.56\n",
            "             :2210Accuracy(Test)=0.528\n",
            "Generation: 2220Accuracy(Training)=0.49\n",
            "             :2220Accuracy(Test)=0.4959\n",
            "Generation: 2230Accuracy(Training)=0.59\n",
            "             :2230Accuracy(Test)=0.6181\n",
            "Generation: 2240Accuracy(Training)=0.66\n",
            "             :2240Accuracy(Test)=0.6055\n",
            "Generation: 2250Accuracy(Training)=0.59\n",
            "             :2250Accuracy(Test)=0.5426\n",
            "Generation: 2260Accuracy(Training)=0.62\n",
            "             :2260Accuracy(Test)=0.5623\n",
            "Generation: 2270Accuracy(Training)=0.54\n",
            "             :2270Accuracy(Test)=0.5862\n",
            "Generation: 2280Accuracy(Training)=0.62\n",
            "             :2280Accuracy(Test)=0.5969\n",
            "Generation: 2290Accuracy(Training)=0.63\n",
            "             :2290Accuracy(Test)=0.5198\n",
            "Generation: 2300Accuracy(Training)=0.59\n",
            "             :2300Accuracy(Test)=0.538\n",
            "Generation: 2310Accuracy(Training)=0.62\n",
            "             :2310Accuracy(Test)=0.4859\n",
            "Generation: 2320Accuracy(Training)=0.55\n",
            "             :2320Accuracy(Test)=0.5022\n",
            "Generation: 2330Accuracy(Training)=0.68\n",
            "             :2330Accuracy(Test)=0.507\n",
            "Generation: 2340Accuracy(Training)=0.51\n",
            "             :2340Accuracy(Test)=0.6068\n",
            "Generation: 2350Accuracy(Training)=0.65\n",
            "             :2350Accuracy(Test)=0.5702\n",
            "Generation: 2360Accuracy(Training)=0.59\n",
            "             :2360Accuracy(Test)=0.5182\n",
            "Generation: 2370Accuracy(Training)=0.54\n",
            "             :2370Accuracy(Test)=0.5353\n",
            "Generation: 2380Accuracy(Training)=0.69\n",
            "             :2380Accuracy(Test)=0.6042\n",
            "Generation: 2390Accuracy(Training)=0.56\n",
            "             :2390Accuracy(Test)=0.5666\n",
            "Generation: 2400Accuracy(Training)=0.68\n",
            "             :2400Accuracy(Test)=0.5964\n",
            "Generation: 2410Accuracy(Training)=0.64\n",
            "             :2410Accuracy(Test)=0.5445\n",
            "Generation: 2420Accuracy(Training)=0.59\n",
            "             :2420Accuracy(Test)=0.5699\n",
            "Generation: 2430Accuracy(Training)=0.63\n",
            "             :2430Accuracy(Test)=0.5388\n",
            "Generation: 2440Accuracy(Training)=0.5\n",
            "             :2440Accuracy(Test)=0.5782\n",
            "Generation: 2450Accuracy(Training)=0.52\n",
            "             :2450Accuracy(Test)=0.5836\n",
            "Generation: 2460Accuracy(Training)=0.6\n",
            "             :2460Accuracy(Test)=0.564\n",
            "Generation: 2470Accuracy(Training)=0.57\n",
            "             :2470Accuracy(Test)=0.5676\n",
            "Generation: 2480Accuracy(Training)=0.54\n",
            "             :2480Accuracy(Test)=0.5287\n",
            "Generation: 2490Accuracy(Training)=0.66\n",
            "             :2490Accuracy(Test)=0.5835\n",
            "Generation: 2500Accuracy(Training)=0.65\n",
            "             :2500Accuracy(Test)=0.6075\n",
            "Generation: 2510Accuracy(Training)=0.57\n",
            "             :2510Accuracy(Test)=0.5254\n",
            "Generation: 2520Accuracy(Training)=0.64\n",
            "             :2520Accuracy(Test)=0.5862\n",
            "Generation: 2530Accuracy(Training)=0.59\n",
            "             :2530Accuracy(Test)=0.5916\n",
            "Generation: 2540Accuracy(Training)=0.59\n",
            "             :2540Accuracy(Test)=0.5856\n",
            "Generation: 2550Accuracy(Training)=0.56\n",
            "             :2550Accuracy(Test)=0.5319\n",
            "Generation: 2560Accuracy(Training)=0.65\n",
            "             :2560Accuracy(Test)=0.6171\n",
            "Generation: 2570Accuracy(Training)=0.57\n",
            "             :2570Accuracy(Test)=0.5237\n",
            "Generation: 2580Accuracy(Training)=0.63\n",
            "             :2580Accuracy(Test)=0.6088\n",
            "Generation: 2590Accuracy(Training)=0.55\n",
            "             :2590Accuracy(Test)=0.5432\n",
            "Generation: 2600Accuracy(Training)=0.59\n",
            "             :2600Accuracy(Test)=0.5304\n",
            "Generation: 2610Accuracy(Training)=0.56\n",
            "             :2610Accuracy(Test)=0.5614\n",
            "Generation: 2620Accuracy(Training)=0.67\n",
            "             :2620Accuracy(Test)=0.6417\n",
            "Generation: 2630Accuracy(Training)=0.63\n",
            "             :2630Accuracy(Test)=0.5283\n",
            "Generation: 2640Accuracy(Training)=0.64\n",
            "             :2640Accuracy(Test)=0.623\n",
            "Generation: 2650Accuracy(Training)=0.67\n",
            "             :2650Accuracy(Test)=0.5892\n",
            "Generation: 2660Accuracy(Training)=0.59\n",
            "             :2660Accuracy(Test)=0.5557\n",
            "Generation: 2670Accuracy(Training)=0.62\n",
            "             :2670Accuracy(Test)=0.5262\n",
            "Generation: 2680Accuracy(Training)=0.74\n",
            "             :2680Accuracy(Test)=0.5852\n",
            "Generation: 2690Accuracy(Training)=0.58\n",
            "             :2690Accuracy(Test)=0.5465\n",
            "Generation: 2700Accuracy(Training)=0.55\n",
            "             :2700Accuracy(Test)=0.6106\n",
            "Generation: 2710Accuracy(Training)=0.64\n",
            "             :2710Accuracy(Test)=0.5712\n",
            "Generation: 2720Accuracy(Training)=0.53\n",
            "             :2720Accuracy(Test)=0.5164\n",
            "Generation: 2730Accuracy(Training)=0.66\n",
            "             :2730Accuracy(Test)=0.5206\n",
            "Generation: 2740Accuracy(Training)=0.65\n",
            "             :2740Accuracy(Test)=0.5584\n",
            "Generation: 2750Accuracy(Training)=0.57\n",
            "             :2750Accuracy(Test)=0.5975\n",
            "Generation: 2760Accuracy(Training)=0.65\n",
            "             :2760Accuracy(Test)=0.5929\n",
            "Generation: 2770Accuracy(Training)=0.63\n",
            "             :2770Accuracy(Test)=0.5787\n",
            "Generation: 2780Accuracy(Training)=0.73\n",
            "             :2780Accuracy(Test)=0.6145\n",
            "Generation: 2790Accuracy(Training)=0.58\n",
            "             :2790Accuracy(Test)=0.591\n",
            "Generation: 2800Accuracy(Training)=0.68\n",
            "             :2800Accuracy(Test)=0.6007\n",
            "Generation: 2810Accuracy(Training)=0.67\n",
            "             :2810Accuracy(Test)=0.6245\n",
            "Generation: 2820Accuracy(Training)=0.62\n",
            "             :2820Accuracy(Test)=0.5695\n",
            "Generation: 2830Accuracy(Training)=0.64\n",
            "             :2830Accuracy(Test)=0.5331\n",
            "Generation: 2840Accuracy(Training)=0.54\n",
            "             :2840Accuracy(Test)=0.5983\n",
            "Generation: 2850Accuracy(Training)=0.64\n",
            "             :2850Accuracy(Test)=0.5698\n",
            "Generation: 2860Accuracy(Training)=0.59\n",
            "             :2860Accuracy(Test)=0.6099\n",
            "Generation: 2870Accuracy(Training)=0.65\n",
            "             :2870Accuracy(Test)=0.6203\n",
            "Generation: 2880Accuracy(Training)=0.65\n",
            "             :2880Accuracy(Test)=0.5597\n",
            "Generation: 2890Accuracy(Training)=0.57\n",
            "             :2890Accuracy(Test)=0.5641\n",
            "Generation: 2900Accuracy(Training)=0.65\n",
            "             :2900Accuracy(Test)=0.5808\n",
            "Generation: 2910Accuracy(Training)=0.63\n",
            "             :2910Accuracy(Test)=0.6457\n",
            "Generation: 2920Accuracy(Training)=0.6\n",
            "             :2920Accuracy(Test)=0.555\n",
            "Generation: 2930Accuracy(Training)=0.65\n",
            "             :2930Accuracy(Test)=0.5534\n",
            "Generation: 2940Accuracy(Training)=0.53\n",
            "             :2940Accuracy(Test)=0.5428\n",
            "Generation: 2950Accuracy(Training)=0.65\n",
            "             :2950Accuracy(Test)=0.6238\n",
            "Generation: 2960Accuracy(Training)=0.62\n",
            "             :2960Accuracy(Test)=0.6134\n",
            "Generation: 2970Accuracy(Training)=0.59\n",
            "             :2970Accuracy(Test)=0.5279\n",
            "Generation: 2980Accuracy(Training)=0.67\n",
            "             :2980Accuracy(Test)=0.5505\n",
            "Generation: 2990Accuracy(Training)=0.59\n",
            "             :2990Accuracy(Test)=0.628\n",
            "Generation: 3000Accuracy(Training)=0.62\n",
            "             :3000Accuracy(Test)=0.5642\n",
            "Generation: 3010Accuracy(Training)=0.67\n",
            "             :3010Accuracy(Test)=0.5956\n",
            "Generation: 3020Accuracy(Training)=0.58\n",
            "             :3020Accuracy(Test)=0.5353\n",
            "Generation: 3030Accuracy(Training)=0.65\n",
            "             :3030Accuracy(Test)=0.6137\n",
            "Generation: 3040Accuracy(Training)=0.69\n",
            "             :3040Accuracy(Test)=0.5867\n",
            "Generation: 3050Accuracy(Training)=0.55\n",
            "             :3050Accuracy(Test)=0.5265\n",
            "Generation: 3060Accuracy(Training)=0.65\n",
            "             :3060Accuracy(Test)=0.6233\n",
            "Generation: 3070Accuracy(Training)=0.66\n",
            "             :3070Accuracy(Test)=0.5904\n",
            "Generation: 3080Accuracy(Training)=0.69\n",
            "             :3080Accuracy(Test)=0.607\n",
            "Generation: 3090Accuracy(Training)=0.67\n",
            "             :3090Accuracy(Test)=0.6067\n",
            "Generation: 3100Accuracy(Training)=0.67\n",
            "             :3100Accuracy(Test)=0.5908\n",
            "Generation: 3110Accuracy(Training)=0.59\n",
            "             :3110Accuracy(Test)=0.5481\n",
            "Generation: 3120Accuracy(Training)=0.65\n",
            "             :3120Accuracy(Test)=0.6338\n",
            "Generation: 3130Accuracy(Training)=0.55\n",
            "             :3130Accuracy(Test)=0.5738\n",
            "Generation: 3140Accuracy(Training)=0.59\n",
            "             :3140Accuracy(Test)=0.6357\n",
            "Generation: 3150Accuracy(Training)=0.55\n",
            "             :3150Accuracy(Test)=0.5284\n",
            "Generation: 3160Accuracy(Training)=0.7\n",
            "             :3160Accuracy(Test)=0.598\n",
            "Generation: 3170Accuracy(Training)=0.6\n",
            "             :3170Accuracy(Test)=0.5605\n",
            "Generation: 3180Accuracy(Training)=0.67\n",
            "             :3180Accuracy(Test)=0.5489\n",
            "Generation: 3190Accuracy(Training)=0.6\n",
            "             :3190Accuracy(Test)=0.6443\n",
            "Generation: 3200Accuracy(Training)=0.61\n",
            "             :3200Accuracy(Test)=0.5692\n",
            "Generation: 3210Accuracy(Training)=0.63\n",
            "             :3210Accuracy(Test)=0.5945\n",
            "Generation: 3220Accuracy(Training)=0.63\n",
            "             :3220Accuracy(Test)=0.5319\n",
            "Generation: 3230Accuracy(Training)=0.61\n",
            "             :3230Accuracy(Test)=0.6046\n",
            "Generation: 3240Accuracy(Training)=0.57\n",
            "             :3240Accuracy(Test)=0.5321\n",
            "Generation: 3250Accuracy(Training)=0.61\n",
            "             :3250Accuracy(Test)=0.5984\n",
            "Generation: 3260Accuracy(Training)=0.65\n",
            "             :3260Accuracy(Test)=0.6074\n",
            "Generation: 3270Accuracy(Training)=0.65\n",
            "             :3270Accuracy(Test)=0.609\n",
            "Generation: 3280Accuracy(Training)=0.61\n",
            "             :3280Accuracy(Test)=0.5546\n",
            "Generation: 3290Accuracy(Training)=0.55\n",
            "             :3290Accuracy(Test)=0.6145\n",
            "Generation: 3300Accuracy(Training)=0.61\n",
            "             :3300Accuracy(Test)=0.552\n",
            "Generation: 3310Accuracy(Training)=0.59\n",
            "             :3310Accuracy(Test)=0.5913\n",
            "Generation: 3320Accuracy(Training)=0.61\n",
            "             :3320Accuracy(Test)=0.5764\n",
            "Generation: 3330Accuracy(Training)=0.6\n",
            "             :3330Accuracy(Test)=0.5391\n",
            "Generation: 3340Accuracy(Training)=0.64\n",
            "             :3340Accuracy(Test)=0.5779\n",
            "Generation: 3350Accuracy(Training)=0.63\n",
            "             :3350Accuracy(Test)=0.5467\n",
            "Generation: 3360Accuracy(Training)=0.68\n",
            "             :3360Accuracy(Test)=0.5926\n",
            "Generation: 3370Accuracy(Training)=0.61\n",
            "             :3370Accuracy(Test)=0.5828\n",
            "Generation: 3380Accuracy(Training)=0.65\n",
            "             :3380Accuracy(Test)=0.6509\n",
            "Generation: 3390Accuracy(Training)=0.68\n",
            "             :3390Accuracy(Test)=0.6398\n",
            "Generation: 3400Accuracy(Training)=0.64\n",
            "             :3400Accuracy(Test)=0.5836\n",
            "Generation: 3410Accuracy(Training)=0.64\n",
            "             :3410Accuracy(Test)=0.5374\n",
            "Generation: 3420Accuracy(Training)=0.6\n",
            "             :3420Accuracy(Test)=0.5698\n",
            "Generation: 3430Accuracy(Training)=0.67\n",
            "             :3430Accuracy(Test)=0.6205\n",
            "Generation: 3440Accuracy(Training)=0.65\n",
            "             :3440Accuracy(Test)=0.582\n",
            "Generation: 3450Accuracy(Training)=0.63\n",
            "             :3450Accuracy(Test)=0.591\n",
            "Generation: 3460Accuracy(Training)=0.63\n",
            "             :3460Accuracy(Test)=0.5693\n",
            "Generation: 3470Accuracy(Training)=0.63\n",
            "             :3470Accuracy(Test)=0.5534\n",
            "Generation: 3480Accuracy(Training)=0.54\n",
            "             :3480Accuracy(Test)=0.6153\n",
            "Generation: 3490Accuracy(Training)=0.63\n",
            "             :3490Accuracy(Test)=0.6256\n",
            "Generation: 3500Accuracy(Training)=0.65\n",
            "             :3500Accuracy(Test)=0.5567\n",
            "Generation: 3510Accuracy(Training)=0.64\n",
            "             :3510Accuracy(Test)=0.5765\n",
            "Generation: 3520Accuracy(Training)=0.67\n",
            "             :3520Accuracy(Test)=0.5422\n",
            "Generation: 3530Accuracy(Training)=0.64\n",
            "             :3530Accuracy(Test)=0.5595\n",
            "Generation: 3540Accuracy(Training)=0.7\n",
            "             :3540Accuracy(Test)=0.6158\n",
            "Generation: 3550Accuracy(Training)=0.62\n",
            "             :3550Accuracy(Test)=0.5861\n",
            "Generation: 3560Accuracy(Training)=0.75\n",
            "             :3560Accuracy(Test)=0.6212\n",
            "Generation: 3570Accuracy(Training)=0.62\n",
            "             :3570Accuracy(Test)=0.6037\n",
            "Generation: 3580Accuracy(Training)=0.7\n",
            "             :3580Accuracy(Test)=0.6443\n",
            "Generation: 3590Accuracy(Training)=0.58\n",
            "             :3590Accuracy(Test)=0.6037\n",
            "Generation: 3600Accuracy(Training)=0.61\n",
            "             :3600Accuracy(Test)=0.5408\n",
            "Generation: 3610Accuracy(Training)=0.66\n",
            "             :3610Accuracy(Test)=0.6119\n",
            "Generation: 3620Accuracy(Training)=0.68\n",
            "             :3620Accuracy(Test)=0.6293\n",
            "Generation: 3630Accuracy(Training)=0.69\n",
            "             :3630Accuracy(Test)=0.5768\n",
            "Generation: 3640Accuracy(Training)=0.61\n",
            "             :3640Accuracy(Test)=0.6076\n",
            "Generation: 3650Accuracy(Training)=0.59\n",
            "             :3650Accuracy(Test)=0.5486\n",
            "Generation: 3660Accuracy(Training)=0.68\n",
            "             :3660Accuracy(Test)=0.6492\n",
            "Generation: 3670Accuracy(Training)=0.62\n",
            "             :3670Accuracy(Test)=0.5821\n",
            "Generation: 3680Accuracy(Training)=0.64\n",
            "             :3680Accuracy(Test)=0.5493\n",
            "Generation: 3690Accuracy(Training)=0.65\n",
            "             :3690Accuracy(Test)=0.6029\n",
            "Generation: 3700Accuracy(Training)=0.63\n",
            "             :3700Accuracy(Test)=0.6342\n",
            "Generation: 3710Accuracy(Training)=0.58\n",
            "             :3710Accuracy(Test)=0.6328\n",
            "Generation: 3720Accuracy(Training)=0.62\n",
            "             :3720Accuracy(Test)=0.6025\n",
            "Generation: 3730Accuracy(Training)=0.68\n",
            "             :3730Accuracy(Test)=0.6333\n",
            "Generation: 3740Accuracy(Training)=0.58\n",
            "             :3740Accuracy(Test)=0.588\n",
            "Generation: 3750Accuracy(Training)=0.65\n",
            "             :3750Accuracy(Test)=0.5616\n",
            "Generation: 3760Accuracy(Training)=0.64\n",
            "             :3760Accuracy(Test)=0.6259\n",
            "Generation: 3770Accuracy(Training)=0.74\n",
            "             :3770Accuracy(Test)=0.6256\n",
            "Generation: 3780Accuracy(Training)=0.59\n",
            "             :3780Accuracy(Test)=0.5947\n",
            "Generation: 3790Accuracy(Training)=0.63\n",
            "             :3790Accuracy(Test)=0.5739\n",
            "Generation: 3800Accuracy(Training)=0.66\n",
            "             :3800Accuracy(Test)=0.5844\n",
            "Generation: 3810Accuracy(Training)=0.69\n",
            "             :3810Accuracy(Test)=0.5762\n",
            "Generation: 3820Accuracy(Training)=0.67\n",
            "             :3820Accuracy(Test)=0.6085\n",
            "Generation: 3830Accuracy(Training)=0.69\n",
            "             :3830Accuracy(Test)=0.6469\n",
            "Generation: 3840Accuracy(Training)=0.67\n",
            "             :3840Accuracy(Test)=0.6862\n",
            "Generation: 3850Accuracy(Training)=0.66\n",
            "             :3850Accuracy(Test)=0.5988\n",
            "Generation: 3860Accuracy(Training)=0.62\n",
            "             :3860Accuracy(Test)=0.6718\n",
            "Generation: 3870Accuracy(Training)=0.66\n",
            "             :3870Accuracy(Test)=0.6225\n",
            "Generation: 3880Accuracy(Training)=0.7\n",
            "             :3880Accuracy(Test)=0.6251\n",
            "Generation: 3890Accuracy(Training)=0.67\n",
            "             :3890Accuracy(Test)=0.645\n",
            "Generation: 3900Accuracy(Training)=0.74\n",
            "             :3900Accuracy(Test)=0.5914\n",
            "Generation: 3910Accuracy(Training)=0.65\n",
            "             :3910Accuracy(Test)=0.6101\n",
            "Generation: 3920Accuracy(Training)=0.69\n",
            "             :3920Accuracy(Test)=0.5944\n",
            "Generation: 3930Accuracy(Training)=0.59\n",
            "             :3930Accuracy(Test)=0.6147\n",
            "Generation: 3940Accuracy(Training)=0.77\n",
            "             :3940Accuracy(Test)=0.6159\n",
            "Generation: 3950Accuracy(Training)=0.65\n",
            "             :3950Accuracy(Test)=0.5561\n",
            "Generation: 3960Accuracy(Training)=0.66\n",
            "             :3960Accuracy(Test)=0.5879\n",
            "Generation: 3970Accuracy(Training)=0.68\n",
            "             :3970Accuracy(Test)=0.6433\n",
            "Generation: 3980Accuracy(Training)=0.6\n",
            "             :3980Accuracy(Test)=0.6575\n",
            "Generation: 3990Accuracy(Training)=0.64\n",
            "             :3990Accuracy(Test)=0.5991\n",
            "Generation: 4000Accuracy(Training)=0.67\n",
            "             :4000Accuracy(Test)=0.5934\n",
            "Generation: 4010Accuracy(Training)=0.66\n",
            "             :4010Accuracy(Test)=0.5931\n",
            "Generation: 4020Accuracy(Training)=0.62\n",
            "             :4020Accuracy(Test)=0.5687\n",
            "Generation: 4030Accuracy(Training)=0.63\n",
            "             :4030Accuracy(Test)=0.6056\n",
            "Generation: 4040Accuracy(Training)=0.64\n",
            "             :4040Accuracy(Test)=0.5987\n",
            "Generation: 4050Accuracy(Training)=0.59\n",
            "             :4050Accuracy(Test)=0.6005\n",
            "Generation: 4060Accuracy(Training)=0.69\n",
            "             :4060Accuracy(Test)=0.6338\n",
            "Generation: 4070Accuracy(Training)=0.66\n",
            "             :4070Accuracy(Test)=0.5903\n",
            "Generation: 4080Accuracy(Training)=0.68\n",
            "             :4080Accuracy(Test)=0.5879\n",
            "Generation: 4090Accuracy(Training)=0.63\n",
            "             :4090Accuracy(Test)=0.6081\n",
            "Generation: 4100Accuracy(Training)=0.64\n",
            "             :4100Accuracy(Test)=0.6368\n",
            "Generation: 4110Accuracy(Training)=0.63\n",
            "             :4110Accuracy(Test)=0.5782\n",
            "Generation: 4120Accuracy(Training)=0.57\n",
            "             :4120Accuracy(Test)=0.5548\n",
            "Generation: 4130Accuracy(Training)=0.7\n",
            "             :4130Accuracy(Test)=0.6501\n",
            "Generation: 4140Accuracy(Training)=0.64\n",
            "             :4140Accuracy(Test)=0.5896\n",
            "Generation: 4150Accuracy(Training)=0.69\n",
            "             :4150Accuracy(Test)=0.6006\n",
            "Generation: 4160Accuracy(Training)=0.65\n",
            "             :4160Accuracy(Test)=0.6086\n",
            "Generation: 4170Accuracy(Training)=0.62\n",
            "             :4170Accuracy(Test)=0.5952\n",
            "Generation: 4180Accuracy(Training)=0.6\n",
            "             :4180Accuracy(Test)=0.6049\n",
            "Generation: 4190Accuracy(Training)=0.64\n",
            "             :4190Accuracy(Test)=0.645\n",
            "Generation: 4200Accuracy(Training)=0.57\n",
            "             :4200Accuracy(Test)=0.58\n",
            "Generation: 4210Accuracy(Training)=0.65\n",
            "             :4210Accuracy(Test)=0.6128\n",
            "Generation: 4220Accuracy(Training)=0.7\n",
            "             :4220Accuracy(Test)=0.6181\n",
            "Generation: 4230Accuracy(Training)=0.66\n",
            "             :4230Accuracy(Test)=0.648\n",
            "Generation: 4240Accuracy(Training)=0.65\n",
            "             :4240Accuracy(Test)=0.609\n",
            "Generation: 4250Accuracy(Training)=0.57\n",
            "             :4250Accuracy(Test)=0.6051\n",
            "Generation: 4260Accuracy(Training)=0.63\n",
            "             :4260Accuracy(Test)=0.6074\n",
            "Generation: 4270Accuracy(Training)=0.66\n",
            "             :4270Accuracy(Test)=0.6235\n",
            "Generation: 4280Accuracy(Training)=0.72\n",
            "             :4280Accuracy(Test)=0.6217\n",
            "Generation: 4290Accuracy(Training)=0.6\n",
            "             :4290Accuracy(Test)=0.6377\n",
            "Generation: 4300Accuracy(Training)=0.67\n",
            "             :4300Accuracy(Test)=0.6277\n",
            "Generation: 4310Accuracy(Training)=0.67\n",
            "             :4310Accuracy(Test)=0.6455\n",
            "Generation: 4320Accuracy(Training)=0.66\n",
            "             :4320Accuracy(Test)=0.6351\n",
            "Generation: 4330Accuracy(Training)=0.63\n",
            "             :4330Accuracy(Test)=0.6261\n",
            "Generation: 4340Accuracy(Training)=0.65\n",
            "             :4340Accuracy(Test)=0.6459\n",
            "Generation: 4350Accuracy(Training)=0.66\n",
            "             :4350Accuracy(Test)=0.6587\n",
            "Generation: 4360Accuracy(Training)=0.72\n",
            "             :4360Accuracy(Test)=0.6154\n",
            "Generation: 4370Accuracy(Training)=0.69\n",
            "             :4370Accuracy(Test)=0.6367\n",
            "Generation: 4380Accuracy(Training)=0.7\n",
            "             :4380Accuracy(Test)=0.7084\n",
            "Generation: 4390Accuracy(Training)=0.65\n",
            "             :4390Accuracy(Test)=0.6059\n",
            "Generation: 4400Accuracy(Training)=0.62\n",
            "             :4400Accuracy(Test)=0.6371\n",
            "Generation: 4410Accuracy(Training)=0.65\n",
            "             :4410Accuracy(Test)=0.6597\n",
            "Generation: 4420Accuracy(Training)=0.62\n",
            "             :4420Accuracy(Test)=0.6238\n",
            "Generation: 4430Accuracy(Training)=0.63\n",
            "             :4430Accuracy(Test)=0.5943\n",
            "Generation: 4440Accuracy(Training)=0.64\n",
            "             :4440Accuracy(Test)=0.6205\n",
            "Generation: 4450Accuracy(Training)=0.69\n",
            "             :4450Accuracy(Test)=0.6278\n",
            "Generation: 4460Accuracy(Training)=0.59\n",
            "             :4460Accuracy(Test)=0.5894\n",
            "Generation: 4470Accuracy(Training)=0.67\n",
            "             :4470Accuracy(Test)=0.564\n",
            "Generation: 4480Accuracy(Training)=0.68\n",
            "             :4480Accuracy(Test)=0.6259\n",
            "Generation: 4490Accuracy(Training)=0.65\n",
            "             :4490Accuracy(Test)=0.6465\n",
            "Generation: 4500Accuracy(Training)=0.54\n",
            "             :4500Accuracy(Test)=0.59\n",
            "Generation: 4510Accuracy(Training)=0.65\n",
            "             :4510Accuracy(Test)=0.5732\n",
            "Generation: 4520Accuracy(Training)=0.67\n",
            "             :4520Accuracy(Test)=0.5805\n",
            "Generation: 4530Accuracy(Training)=0.68\n",
            "             :4530Accuracy(Test)=0.6413\n",
            "Generation: 4540Accuracy(Training)=0.74\n",
            "             :4540Accuracy(Test)=0.6078\n",
            "Generation: 4550Accuracy(Training)=0.63\n",
            "             :4550Accuracy(Test)=0.6391\n",
            "Generation: 4560Accuracy(Training)=0.75\n",
            "             :4560Accuracy(Test)=0.6597\n",
            "Generation: 4570Accuracy(Training)=0.63\n",
            "             :4570Accuracy(Test)=0.6443\n",
            "Generation: 4580Accuracy(Training)=0.66\n",
            "             :4580Accuracy(Test)=0.6215\n",
            "Generation: 4590Accuracy(Training)=0.6\n",
            "             :4590Accuracy(Test)=0.6268\n",
            "Generation: 4600Accuracy(Training)=0.51\n",
            "             :4600Accuracy(Test)=0.6315\n",
            "Generation: 4610Accuracy(Training)=0.73\n",
            "             :4610Accuracy(Test)=0.6612\n",
            "Generation: 4620Accuracy(Training)=0.73\n",
            "             :4620Accuracy(Test)=0.6456\n",
            "Generation: 4630Accuracy(Training)=0.62\n",
            "             :4630Accuracy(Test)=0.5248\n",
            "Generation: 4640Accuracy(Training)=0.64\n",
            "             :4640Accuracy(Test)=0.5688\n",
            "Generation: 4650Accuracy(Training)=0.72\n",
            "             :4650Accuracy(Test)=0.6047\n",
            "Generation: 4660Accuracy(Training)=0.61\n",
            "             :4660Accuracy(Test)=0.5903\n",
            "Generation: 4670Accuracy(Training)=0.66\n",
            "             :4670Accuracy(Test)=0.6292\n",
            "Generation: 4680Accuracy(Training)=0.63\n",
            "             :4680Accuracy(Test)=0.6158\n",
            "Generation: 4690Accuracy(Training)=0.7\n",
            "             :4690Accuracy(Test)=0.616\n",
            "Generation: 4700Accuracy(Training)=0.61\n",
            "             :4700Accuracy(Test)=0.6938\n",
            "Generation: 4710Accuracy(Training)=0.63\n",
            "             :4710Accuracy(Test)=0.618\n",
            "Generation: 4720Accuracy(Training)=0.61\n",
            "             :4720Accuracy(Test)=0.6467\n",
            "Generation: 4730Accuracy(Training)=0.65\n",
            "             :4730Accuracy(Test)=0.639\n",
            "Generation: 4740Accuracy(Training)=0.69\n",
            "             :4740Accuracy(Test)=0.6738\n",
            "Generation: 4750Accuracy(Training)=0.69\n",
            "             :4750Accuracy(Test)=0.6427\n",
            "Generation: 4760Accuracy(Training)=0.64\n",
            "             :4760Accuracy(Test)=0.5813\n",
            "Generation: 4770Accuracy(Training)=0.65\n",
            "             :4770Accuracy(Test)=0.5929\n",
            "Generation: 4780Accuracy(Training)=0.71\n",
            "             :4780Accuracy(Test)=0.6808\n",
            "Generation: 4790Accuracy(Training)=0.63\n",
            "             :4790Accuracy(Test)=0.5505\n",
            "Generation: 4800Accuracy(Training)=0.68\n",
            "             :4800Accuracy(Test)=0.6528\n",
            "Generation: 4810Accuracy(Training)=0.68\n",
            "             :4810Accuracy(Test)=0.6984\n",
            "Generation: 4820Accuracy(Training)=0.66\n",
            "             :4820Accuracy(Test)=0.6381\n",
            "Generation: 4830Accuracy(Training)=0.64\n",
            "             :4830Accuracy(Test)=0.6145\n",
            "Generation: 4840Accuracy(Training)=0.7\n",
            "             :4840Accuracy(Test)=0.6\n",
            "Generation: 4850Accuracy(Training)=0.66\n",
            "             :4850Accuracy(Test)=0.6191\n",
            "Generation: 4860Accuracy(Training)=0.62\n",
            "             :4860Accuracy(Test)=0.6259\n",
            "Generation: 4870Accuracy(Training)=0.61\n",
            "             :4870Accuracy(Test)=0.6387\n",
            "Generation: 4880Accuracy(Training)=0.67\n",
            "             :4880Accuracy(Test)=0.6249\n",
            "Generation: 4890Accuracy(Training)=0.58\n",
            "             :4890Accuracy(Test)=0.5582\n",
            "Generation: 4900Accuracy(Training)=0.76\n",
            "             :4900Accuracy(Test)=0.6308\n",
            "Generation: 4910Accuracy(Training)=0.73\n",
            "             :4910Accuracy(Test)=0.6175\n",
            "Generation: 4920Accuracy(Training)=0.63\n",
            "             :4920Accuracy(Test)=0.5877\n",
            "Generation: 4930Accuracy(Training)=0.74\n",
            "             :4930Accuracy(Test)=0.6414\n",
            "Generation: 4940Accuracy(Training)=0.6\n",
            "             :4940Accuracy(Test)=0.6148\n",
            "Generation: 4950Accuracy(Training)=0.64\n",
            "             :4950Accuracy(Test)=0.5525\n",
            "Generation: 4960Accuracy(Training)=0.61\n",
            "             :4960Accuracy(Test)=0.5726\n",
            "Generation: 4970Accuracy(Training)=0.61\n",
            "             :4970Accuracy(Test)=0.628\n",
            "Generation: 4980Accuracy(Training)=0.67\n",
            "             :4980Accuracy(Test)=0.6034\n",
            "Generation: 4990Accuracy(Training)=0.62\n",
            "             :4990Accuracy(Test)=0.5735\n",
            "Generation: 5000Accuracy(Training)=0.71\n",
            "             :5000Accuracy(Test)=0.6372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x85n3tbEHIJx"
      },
      "source": [
        "# `グラフ表示`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyhXc8FJueE0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5e7bf193-d5ca-4d71-d43a-b8898db2b746"
      },
      "source": [
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, accuracies_train, label=\"training set\")\n",
        "plt.plot(lists, accuracies_test,  label=\"test set\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.title(\"accuracy\")\n",
        "plt.xlabel(\"count\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "# グラフの表示\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8AH400idpTk"
      },
      "source": [
        "# 終わり"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdBIu4za5umf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f71588f-9bfc-4a9d-8a5a-590c544d7f99"
      },
      "source": [
        "#終了時刻\n",
        "finish_time = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "print(\"finish_time=\",finish_time)\n",
        "print(\"total_time=\",finish_time-start_time)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish_time= 2021-04-28 23:12:21.464983+09:00\n",
            "total_time= 0:00:32.422847\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}